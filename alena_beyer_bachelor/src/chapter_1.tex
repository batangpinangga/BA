\chapter{Introduction}
\label{chap:introduction}

\section{Motivation}
% I: Importance of information visualization
Information Visualization as a method to analyze data has been popular for some time now. At first only a research area, it is now used in many application areas. Likewise companies are discovering the value of data analysis and visualization. The aim is use data analysis to better understand their businesses. In particular, interactive visual data exploration - also called data discovery - has gained importance, as the analyst can not only display data but interactively adapt views and parameters according to his needs\footnote{In the BARC BI Trend Monitor 2017 Data discovery and visualization is ranked most important (7,2 from 10) by 2,800 users, companies and software vendors \cite{Bange2016}.}.
\par
% I: Multi-variate data is 
One important research area for companies is the visualization of multivariate time-oriented data. Even though application areas for business data are manifold, one commonality is the collection and analysis of time-dependent data. Streaming Data is one famous example of time-dependent data as it denotes continually arriving data (marked with a timestamp), which is usually of massive data volume  \cite{Callaghan2002}. As streaming data can appear in various domains such as customer data,  smart manufacturing,  fraud detection,  the internet of things or risk management time-oriented data is highly relevant for business. 
\par 
% I: Tools
Companies usually analyze their data with the help of visualization tools or frameworks. These tools allow users for exploring their data interactively with the help of visualization. These tools promote themselves as self-service data science tools. They promise that anyone would be able to perform data analysis - no programming skills are required. Such tools offer all the necessities for visual analysis. Frameworks however require more programming skills but offer more features.
\par
% I: challenges by Big Data
Yet, interactive visual analysis in the Big Data era is challenging. As sensors can collect data automatically and mobile devices are popular, massive amounts of data are collected in business application areas such as smart phones, machines or cars
\footnote{While out of 1000 surveyed companies only 5.4\% of the firms invested more than \$50MM in Big Data in 2014,  this share rose to 26, 8\% in 2017  \cite{Bean2016}.}. When this data is visually explored the size of the data leads to problems. With a limited screen resolution the data volume greatly exceeds the number of screen pixels, causing visual clutter. Visual clutter in turn hinders the data analyst in finding patterns, in discerning objects and in abstracting data to clusters, trends or correlations. 
\par
% I: Example of Fault Detection
As an example from the automobile industry: modern  vehicles typically perform ongoing collection of data via the car's sensors. These data sets are then used for various purposes such as error detection. If the motor oil sensor measures that the oil is low a corresponding signal will automatically appear in the electronic instrument cluster. If the mileage is above a determined level the driver is requested to visit the garage. All these error signals are emitted from the error memory in the car which is manually implemented during the vehicle's development. However, during development, engineers are typically not yet familiar with error thresholds. Therefore, visual data exploration is a method to detect outliers and determine threshold values. Yet, visualization in this context is challenging as the car's sensors emit signals with very high frequency and a resulting massive data volume. Where large scale visualizations exist, visual exploration can support developers by revealing patterns and outliers. Thus,  the need for scalable visualizations and appropriate tools becomes obvious. 
In order to reduce the visual clutter visualization techniques and visualization tools need to adapt to large data sets and offer appropriate methods to present data.
\par

\section{Research Question}\label{research}
Thus, the research question of this work is the visualization of large data sets which overcomes perceptual limitations and how current visualization tools and frameworks support it. This work focuses on time-oriented data. 
As time-oriented data is characterized by high volume the question arises whether the tools used in business are able to display large time-oriented data sets to the business user in an effective manner. The term effectiveness is defined in \ref{effective}. 
We suppose that visualization tools and frameworks require programming knowledge.
The aim of this work is to approach the research question above by characterizing the data, by studying the business user and different visualization techniques. Based on this analysis, requirements for the visualization of large time-oriented data are derived. These requirements are applied in the comparison of a selection of state-of-the-art tools that are used in companies for the analysis of business data.
\section{Structure of this work}
Chapter \ref{chap:concepts} includes definitions that are used throughout this thesis and  summarises the existing publications that relate to these definitions. In chapter \ref{chap:basics} the characteristics of time-oriented data are analyzed. The main part of this work is dealt with in the two succeeding sections with the visualization of large scaled data (chapter \ref{chap:scalability}) and the tool comparison (chapter \ref{chap:Tools}). 
Based on the tool discussion a conclusion is derived in chapter \ref{chap:conclusion}.
As this work only covers one specific part of visual exploration of large data chapter \ref{chap:conclusion} covers limitations of this work and resulting future work.
